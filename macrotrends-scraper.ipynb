{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4b8674-3a64-4411-8482-f28310839f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCRAPE MULTIPLE FINANCIAL PARAMETERS FROM SINGLE PAGE / V2 / Faster scrolling using drag&drop apprach\n",
    "#https://stackoverflow.com/questions/62119348/how-to-scroll-horizontally-using-selenium-chromedriver-in-python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from html.parser import HTMLParser\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b67a964",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: PEP_financial_statements_quarter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-655470852325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;31m# DatabaseOperations.drop_table(input_data='tickers_data') #remove table from database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;31m# DatabaseOperations.get_database_tables()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m \u001b[0mDatabaseOperations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_ticker_name_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PEP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-655470852325>\u001b[0m in \u001b[0;36mdrop_ticker_name_tables\u001b[1;34m(ticker_name)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[1;31m# print(ticker_name+item)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;31m# DatabaseOperations.drop_table(ticker_name + item)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;31m# company_data.dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-655470852325>\u001b[0m in \u001b[0;36mdrop_table\u001b[1;34m(input_data)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;31m#Doping EMPLOYEE table if already exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"DROP TABLE {input_data}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table {input_data} dropped... \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: PEP_financial_statements_quarter"
     ]
    }
   ],
   "source": [
    "#MAIN SCRAPPER\n",
    "\n",
    "database_file = 'company_database.db'\n",
    "\n",
    "#HTML parser that help to parse html-strings\n",
    "#https://www.educative.io/answers/what-is-the-html-parser-in-python\n",
    "class Parser(HTMLParser):\n",
    "  def handle_data(self, data):\n",
    "    self.output = data\n",
    "parser = Parser()\n",
    "\n",
    "\n",
    "class ScrapeMacrotrend():\n",
    "\n",
    "    def __init__(self, ticker_search, scrape_again=False):\n",
    "        \n",
    "        url = self.get_company_page_url(ticker_search) #find url for the respective company based on ticker-name\n",
    "        # url = 'https://www.macrotrends.net/stocks/charts/TSLA/tesla/income-statement?freq=Q'\n",
    "\n",
    "\n",
    "        #scrape and store company quarter data if not available in database. If data already exists in database, return it from there.\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_statements_quarter'))==False or scrape_again==True:\n",
    "            self.financial_statements_quarter = self.scrape_the_data(url + '/income-statement?freq=Q')\n",
    "            self.store_data_in_database(data=self.financial_statements_quarter, name= (ticker_search + '_financial_statements_quarter'))\n",
    "        else:\n",
    "            self.financial_statements_quarter = self.get_from_database(name= (ticker_search + '_financial_statements_quarter'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_balance_sheet_quarter'))==False or scrape_again==True:\n",
    "            self.balance_sheet_quarter = self.scrape_the_data(url + '/balance-sheet?freq=Q')\n",
    "            self.store_data_in_database(data=self.balance_sheet_quarter, name= (ticker_search + '_balance_sheet_quarter'))\n",
    "        else:\n",
    "            self.balance_sheet_quarter = self.get_from_database(name= (ticker_search + '_balance_sheet_quarter'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_cash_flow_quarter'))==False or scrape_again==True:\n",
    "            self.cash_flow_quarter = self.scrape_the_data(url + '/cash-flow-statement?freq=Q')\n",
    "            self.store_data_in_database(data=self.cash_flow_quarter, name= (ticker_search + '_cash_flow_quarter'))\n",
    "        else:\n",
    "            self.cash_flow_quarter = self.get_from_database(name= (ticker_search + '_cash_flow_quarter'))\n",
    "\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_ratios_quarter'))==False or scrape_again==True:\n",
    "            self.financial_ratios_quarter = self.scrape_the_data(url + '/financial-ratios?freq=Q')\n",
    "            self.store_data_in_database(data=self.financial_ratios_quarter, name= (ticker_search + '_financial_ratios_quarter'))\n",
    "        else:\n",
    "            self.financial_ratios_quarter = self.get_from_database(name= (ticker_search + '_financial_ratios_quarter'))\n",
    "        \n",
    "        #scrape company anual data\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_statements_annual'))==False or scrape_again==True:\n",
    "            self.financial_statements_annual = self.scrape_the_data(url + '/income-statement?freq=A')\n",
    "            self.store_data_in_database(data=self.financial_statements_annual, name= (ticker_search + '_financial_statements_annual'))\n",
    "        else:\n",
    "            self.financial_statements_annual = self.get_from_database(name= (ticker_search + '_financial_statements_annual'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_balance_sheet_annual'))==False or scrape_again==True:\n",
    "            self.balance_sheet_annual = self.scrape_the_data(url + '/balance-sheet?freq=A')\n",
    "            self.store_data_in_database(data=self.balance_sheet_annual, name= (ticker_search + '_balance_sheet_annual'))\n",
    "        else:\n",
    "            self.balance_sheet_annual = self.get_from_database(name= (ticker_search + '_balance_sheet_annual'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_cash_flow_annual'))==False or scrape_again==True:\n",
    "            self.cash_flow_annual = self.scrape_the_data(url + '/cash-flow-statement?freq=A')\n",
    "            self.store_data_in_database(data=self.cash_flow_annual, name= (ticker_search + '_cash_flow_annual'))\n",
    "        else:\n",
    "            self.cash_flow_annual = self.get_from_database(name= (ticker_search + '_cash_flow_annual'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_ratios_annual'))==False or scrape_again==True:\n",
    "            self.financial_ratios_annual = self.scrape_the_data(url + '/financial-ratios?freq=A')\n",
    "            self.store_data_in_database(data=self.financial_ratios_annual, name= (ticker_search + '_financial_ratios_annual'))\n",
    "        else:\n",
    "            self.financial_ratios_annual = self.get_from_database(name= (ticker_search + '_financial_ratios_annual'))\n",
    "\n",
    "    def get_company_page_url_old(self, ticker_search):\n",
    "        #get ticker data\n",
    "        tickers_url = 'https://www.macrotrends.net/assets/php/ticker_search_list.php?_=1664947632720'\n",
    "        data_tickers = requests.get(tickers_url)\n",
    "        data_tickers = data_tickers.text\n",
    "        data_tickers_json = json.loads(data_tickers)\n",
    "\n",
    "        #search for the company-url\n",
    "        for item in data_tickers_json:\n",
    "            # print(item['s'])\n",
    "            if ticker_search in item['s']: #example: AAPL/apple\n",
    "                company_page_url = item['s']\n",
    "                # print(\"company-url={}\".format(company_page_url))\n",
    "\n",
    "        return 'https://www.macrotrends.net/stocks/charts/' + company_page_url\n",
    "\n",
    "    def get_company_page_url(self, ticker_search):\n",
    "\n",
    "        self.tickers_data = self.get_from_database('tickers_data') #get tickers-data from database\n",
    "        if self.tickers_data is None: #if tickers-data not found in database\n",
    "            print(f'tickers-data not found in {database_file}')\n",
    "            self.tickers_data = self.download_tickers()\n",
    "            self.store_data_in_database(self.tickers_data, \"tickers_data\")\n",
    "\n",
    "        else: #if tickers-data exists in database\n",
    "            print(f'tickers-data found in {database_file}')\n",
    "            # print(self.tickers_data)\n",
    "\n",
    "        output = self.tickers_data.loc[self.tickers_data['ticker_name'] == ticker_search]\n",
    "        ticker_name = output['ticker_name'].values[0] #get ticker-name\n",
    "        company_name = output['company_name'].values[0] #get company-name\n",
    "        # print(ticker_name, company_name)\n",
    "\n",
    "        return'https://www.macrotrends.net/stocks/charts/' + ticker_name + '/' + company_name\n",
    "\n",
    "    def download_tickers(self):\n",
    "        ticker_name = [] #store ticker-names f.e. 'APPL'\n",
    "        company_name = [] #store company-names f.e. 'apple'\n",
    "        tickers_url = 'https://www.macrotrends.net/assets/php/ticker_search_list.php?_=1664947632720' #donwnload ticker-page\n",
    "        \n",
    "        data_tickers = requests.get(tickers_url) #download tickers-page\n",
    "        data_tickers = data_tickers.text #convert it to text\n",
    "        data_tickers_json = json.loads(data_tickers) #convert the text to json-format\n",
    "\n",
    "        for item in data_tickers_json: #loop over each item in json-format\n",
    "            ticker_name_temp = item['s'].split('/')[0] #get ticker-name from current item\n",
    "            company_name_temp = item['s'].split('/')[1] #get company-name from current item\n",
    "\n",
    "            ticker_name.append(ticker_name_temp) #append ticker-name to list\n",
    "            company_name.append(company_name_temp) #append company-name to list\n",
    "\n",
    "        data = {'ticker_name':ticker_name, 'company_name':company_name} #store in dictionary\n",
    "        output = pd.DataFrame(data)\n",
    "        return output\n",
    "\n",
    "    def scrape_the_data(self, url):\n",
    "\n",
    "        page = requests.get(url)\n",
    "        page_lines = page.text.splitlines()\n",
    "        for line in page_lines:\n",
    "            if 'var originalData =' in line: #the line where all the data is storred\n",
    "                data = line #store the information in a variable\n",
    "                print(f'line={url, line[0:100]}')\n",
    "\n",
    "        data = data[20:-1] # remove the the unneeded informatino from the line\n",
    "        data_json = json.loads(data) #convert the line to a json-object\n",
    "\n",
    "        #the following vars are needed when looping through the json_\n",
    "        data_index = [] #collect the data-names\n",
    "        data_column = [] #collect the data-dates\n",
    "        data_values = [] #collect the data-values\n",
    "\n",
    "        #loop over \n",
    "        for item in data_json:\n",
    "\n",
    "            #reset temp-vars for the next loop\n",
    "            data_values_temp = [] #store data-values for current loop\n",
    "            data_column_temp = [] #store data-dates for current loop\n",
    "\n",
    "            for key in item.items() :\n",
    "                # print(key[0], key[1])\n",
    "\n",
    "                if (key[0] != 'field_name') and (key[0] != 'popup_icon'): # dates and values\n",
    "                    # print(key[0], key[1])\n",
    "                    data_column_temp.append(key[0]) #dates\n",
    "                    data_values_temp.append(key[1]) #values\n",
    "\n",
    "                elif key[0] == 'field_name': #data-names\n",
    "                    # print(key[1])\n",
    "                    parser.feed(key[1])\n",
    "                    # print(parser.output)\n",
    "                    data_index.append(parser.output) # xxx = \"<a href='/stocks/charts/TSLA/tesla/cost-goods-sold'>Cost Of Goods Sold</a>\"\n",
    "\n",
    "                elif key[0]== 'popup_icon': #data-graph link (not needed)\n",
    "                    continue\n",
    "                    print(key[1])\n",
    "\n",
    "            #add temp-vars to permanent ones\n",
    "            data_values.append(data_values_temp)\n",
    "            data_column.append(data_column_temp)\n",
    "\n",
    "\n",
    "        # pd.DataFrame(data=data_values, index=data_index, columns=data_column, dtype=None, copy=None)\n",
    "        company_data = pd.DataFrame(data=data_values, index=data_index, columns=data_column[0])\n",
    "        company_data.apply(self.fixData)\n",
    "\n",
    "        return company_data\n",
    "\n",
    "    #apply-function that goes over all dataframe-elements and converts them to numeric value if possible\n",
    "    def fixData(sekf, input_data):\n",
    "        \n",
    "        for i in range(len(input_data)):\n",
    "        \n",
    "            try:\n",
    "                input_data[i] = pd.to_numeric(input_data[i])\n",
    "                # print(type(input_data[i]), \"converted to numeric\")\n",
    "\n",
    "            except:\n",
    "                # pass\n",
    "                print(input_data[i], \"Can't convert to numeric\")\n",
    "            \n",
    "        return input_data\n",
    "        \n",
    "    def store_data_in_database(self, data, name):\n",
    "        print(f'Storring {name} in {database_file}')\n",
    "        conn = sqlite3.connect(database_file) #connect to sqlite3-database\n",
    "        data.to_sql(name=name, con=conn, if_exists='replace',  index=False) #store dataframe to sqlite-database\n",
    "        conn.close()\n",
    "\n",
    "    def data_already_in_database(self, name):\n",
    "\n",
    "        output = False\n",
    "        conn = sqlite3.connect('company_database.db')\n",
    "        c = conn.cursor()\n",
    "                    \n",
    "        #get the count of tables with the name\n",
    "        c.execute(''' SELECT count(name) FROM sqlite_master WHERE type='table' AND name='{}' '''.format(name))\n",
    "\n",
    "        #if the count is 1, then table exists\n",
    "        if c.fetchone()[0]==1:\n",
    "            # print('Table exists.', name)\n",
    "            output = True\n",
    "\t\t\t\n",
    "        #commit the changes to db\t\t\t\n",
    "        conn.commit()\n",
    "        #close the connection\n",
    "        conn.close()\n",
    "\n",
    "        # print(name, output)\n",
    "        return output\n",
    "\n",
    "    def get_from_database(self, name):\n",
    "        conn = sqlite3.connect(database_file)\n",
    "\n",
    "        try: #get the data from database and put it in pandas-dataframe\n",
    "            output = pd.read_sql_query(f\"SELECT * from {name}\", conn) \n",
    "        except : #if data not available, return None\n",
    "            print(f'ERROR: {name}, not found in {database_file}')\n",
    "            conn.close()\n",
    "            return None\n",
    "\n",
    "        if name != 'tickers_data': #if dataframe is not tickers-data(ticker-names) but company-data(financial-statement, balance sheet etc)\n",
    "            output = output.set_index('index', inplace=False) #set the index-column as dataframe-index, needed because otherwise the dataframe index won't be parameter names but integers\n",
    "        conn.close()\n",
    "        return output\n",
    "\n",
    "\n",
    "class DatabaseOperations():\n",
    "\n",
    "    def drop_table(input_data):\n",
    "        #Connecting to sqlite\n",
    "\n",
    "        conn = sqlite3.connect(database_file)\n",
    "\n",
    "        #Creating a cursor object using the cursor() method\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        #Doping EMPLOYEE table if already exists\n",
    "        cursor.execute(f\"DROP TABLE {input_data}\")\n",
    "        print(f\"Table {input_data} dropped... \")\n",
    "\n",
    "        #Commit your changes in the database\n",
    "        conn.commit()\n",
    "\n",
    "        #Closing the connection\n",
    "        conn.close()\n",
    "\n",
    "    def get_database_tables():\n",
    "\n",
    "        con = sqlite3.connect(database_file)\n",
    "        cursor = con.cursor()\n",
    "\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        print(cursor.fetchall())\n",
    "\n",
    "    def drop_ticker_name_tables(ticker_name):\n",
    "        tables_names = ['_financial_statements_quarter', '_balance_sheet_quarter', '_cash_flow_quarter', '_financial_ratios_quarter',\n",
    "                        '_financial_statements_annual', '_balance_sheet_annual', '_cash_flow_annual', '_financial_ratios_annual']\n",
    "\n",
    "        for item in tables_names:\n",
    "            # print(ticker_name+item)\n",
    "            # DatabaseOperations.drop_table(ticker_name + item)\n",
    "            __class__.drop_table(ticker_name + item)\n",
    "            \n",
    "    # company_data.dtypes\n",
    "    # company_data.columns\n",
    "    # company_data.index\n",
    "\n",
    "    # company_data.loc['Revenue']\n",
    "    # company_data.loc['EPS - Earnings Per Share']\n",
    "\n",
    "    # company_data.columns = pd.to_datetime(company_data.columns) #change columns data-type to datetime.\n",
    "    # company_data.columns\n",
    "\n",
    "# pepsi_data = ScrapeMacrotrend(ticker_search='PEP', scrape_again=False)\n",
    "\n",
    "# DatabaseOperations.drop_table(input_data='tickers_data') #remove table from database\n",
    "# DatabaseOperations.get_database_tables()\n",
    "DatabaseOperations.drop_ticker_name_tables(ticker_name='PEP')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data = ScrapeMacrotrend('AAPL')\n",
    "tesla_data = ScrapeMacrotrend('TSLA')\n",
    "microsoft_data = ScrapeMacrotrend('MSFT')\n",
    "amazon_data = ScrapeMacrotrend('AMZN')\n",
    "# google_data = ScrapeMacrotrend('GOOG')\n",
    "\n",
    "# apple_data1 = ScrapeMacrotrend('AAPL')\n",
    "# tesla_data1 = ScrapeMacrotrend('TSLA')\n",
    "# microsoft_data1 = ScrapeMacrotrend('MSFT')\n",
    "# amazon_data1 = ScrapeMacrotrend(ticker_search='AMZN')\n",
    "\n",
    "#tesla_data.financial_statements_annual\n",
    "# print(amazon_data.financial_statements_quarter.index.to_list())\n",
    "# print(amazon_data1.financial_statements_quarter.index.to_list())\n",
    "\n",
    "# amazon_data.financial_statements_quarter.columns\n",
    "\n",
    "# amazon_data2 = amazon_data1.financial_statements_quarter.copy()\n",
    "# print(amazon_data2.columns)\n",
    "# amazon_data2.drop('index', axis=1, inplace=True) \n",
    "# amazon_data2.set_index('index', inplace=True)\n",
    "# print(amazon_data2.columns)\n",
    "\n",
    "# amazon_data.financial_statements_quarter\n",
    "# amazon_data1.financial_statements_quarter\n",
    "# amazon_data2\n",
    "\n",
    "# amazon_data3 = ScrapeMacrotrend(ticker_search='AMZN')\n",
    "# amazon_data3.financial_statements_quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46832d9-cc4e-4c87-9c83-76bec4211338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the data\n",
    "plt.figure(figsize=(20,8)) #set figure size\n",
    "\n",
    "# tesla_data.financial_ratios_quarter.loc['Current Ratio'].plot()\n",
    "# apple_data.financial_ratios_quarter.loc['Current Ratio'].plot()\n",
    "\n",
    "print(tesla_data.financial_statements_annual.index[0])\n",
    "param_name = tesla_data.financial_statements_annual.index[4] #get parameter name from dataframe columns\n",
    "\n",
    "tesla_data.financial_statements_annual.loc[param_name].plot()\n",
    "apple_data.financial_statements_annual.loc[param_name].plot()\n",
    "microsoft_data.financial_statements_annual.loc[param_name].plot()\n",
    "amazon_data.financial_statements_annual.loc[param_name].plot()\n",
    "google_data.financial_statements_annual.loc[param_name].plot()\n",
    "plt.plot()\n",
    "\n",
    "#invert x-axis (2009 on the left, 2022 on the right)\n",
    "ax = plt.gca()\n",
    "ax.invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4ccf1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers-data found in company_database.db\n",
      "     ticker_name                    company_name\n",
      "0           AAPL                           apple\n",
      "1           MSFT                       microsoft\n",
      "2           GOOG                        alphabet\n",
      "3          GOOGL                        alphabet\n",
      "4           AMZN                          amazon\n",
      "...          ...                             ...\n",
      "6174         BUR                 burford-capital\n",
      "6175        BCSF  bain-capital-specialty-finance\n",
      "6176        SIOX                axovant-sciences\n",
      "6177        ARLP      alliance-resource-partners\n",
      "6178         ACH               aluminum-of-china\n",
      "\n",
      "[6179 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get all ticker-urls and put them in the database\n",
    "\n",
    "from sqlite3 import DatabaseError, OperationalError\n",
    "\n",
    "\n",
    "class getTickersData():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # self.tickers_data = self.download_tickers()\n",
    "        # self.store_data_in_database(self.tickers_data, \"Macrotrends_Tickers_URLs\")\n",
    "\n",
    "        self.tickers_data = self.get_from_database('tickers_data') #get tickers-data from database\n",
    "        if self.tickers_data is None: #if tickers-data not found in database\n",
    "            print(f'tickers-data not found in {database_file}')\n",
    "            self.tickers_data = self.download_tickers()\n",
    "            self.store_data_in_database(self.tickers_data, \"tickers_data\")\n",
    "\n",
    "        else: #if tickers-data exists in database\n",
    "            print(f'tickers-data found in {database_file}')\n",
    "            print(self.tickers_data)\n",
    "\n",
    "    def download_tickers(self):\n",
    "        ticker_name = [] #store ticker-names f.e. 'APPL'\n",
    "        company_name = [] #store company-names f.e. 'apple'\n",
    "        tickers_url = 'https://www.macrotrends.net/assets/php/ticker_search_list.php?_=1664947632720' #donwnload ticker-page\n",
    "        \n",
    "        data_tickers = requests.get(tickers_url) #download tickers-page\n",
    "        data_tickers = data_tickers.text #convert it to text\n",
    "        data_tickers_json = json.loads(data_tickers) #convert the text to json-format\n",
    "\n",
    "        for item in data_tickers_json: #loop over each item in json-format\n",
    "            ticker_name_temp = item['s'].split('/')[0] #get ticker-name from current item\n",
    "            company_name_temp = item['s'].split('/')[1] #get company-name from current item\n",
    "\n",
    "            ticker_name.append(ticker_name_temp) #append ticker-name to list\n",
    "            company_name.append(company_name_temp) #append company-name to list\n",
    "\n",
    "        data = {'ticker_name':ticker_name, 'company_name':company_name} #store in dictionary\n",
    "        output = pd.DataFrame(data)\n",
    "        return output\n",
    "\n",
    "    def store_data_in_database(self, data, name):\n",
    "        conn = sqlite3.connect(database_file) #connect to sqlite3-database\n",
    "        data.to_sql(name=name, con=conn, if_exists='replace',  index=False) #store dataframe to sqlite-database\n",
    "        conn.close()\n",
    "    \n",
    "    def get_from_database(self, name):\n",
    "        conn = sqlite3.connect(database_file)\n",
    "        try:\n",
    "            output = pd.read_sql_query(f\"SELECT * from {name}\", conn) #get the data from database and put it in pandas-dataframe\n",
    "        except :\n",
    "            print(f'ERROR: {name}, not found in {database_file}')\n",
    "            conn.close()\n",
    "            return None\n",
    "\n",
    "        # output_index = output.set_index('index', inplace=False) #set the index-column as dataframe-index, needed because otherwise the dataframe index won't be parameter names but integers\n",
    "        conn.close()\n",
    "        # print(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "        \n",
    "output = getTickersData()\n",
    "# print(output.tickers_data.iloc[1][0])\n",
    "# ticker_num_rows= len(output.tickers_data)\n",
    "# for i in range (150): #ticker_num_rows):\n",
    "#     ticker_name = str(output.tickers_data.iloc[i][0]).split('/')[0]\n",
    "#     print(ticker_name)\n",
    "#     try:\n",
    "#         ScrapeMacrotrend(ticker_name)\n",
    "#     except:\n",
    "#         print(f\"can't scrape{ticker_name}\")\n",
    "#     time.sleep(0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.tickers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b06c6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = dict()\n",
    "f'{foo=}'.split('=')[0]\n",
    "'foo' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c1ea65e26ef28b28e64095c9e5432f906157cd0ea853e6f943e47ec1b4a1819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
