{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b8674-3a64-4411-8482-f28310839f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCRAPE MULTIPLE FINANCIAL PARAMETERS FROM SINGLE PAGE / V2 / Faster scrolling using drag&drop apprach\n",
    "#https://stackoverflow.com/questions/62119348/how-to-scroll-horizontally-using-selenium-chromedriver-in-python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from html.parser import HTMLParser\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape the data\n",
    "\n",
    "#HTML parser that help to parse html-strings\n",
    "#https://www.educative.io/answers/what-is-the-html-parser-in-python\n",
    "class Parser(HTMLParser):\n",
    "  def handle_data(self, data):\n",
    "    self.output = data\n",
    "parser = Parser()\n",
    "\n",
    "\n",
    "class ScrapeMacrotrend():\n",
    "\n",
    "    def __init__(self, ticker_search, scrape_again=False):\n",
    "        \n",
    "        url = self.get_company_page_url(ticker_search) #find url for the respective company based on ticker-name\n",
    "        # url = 'https://www.macrotrends.net/stocks/charts/TSLA/tesla/income-statement?freq=Q'\n",
    "\n",
    "        #scrape and store company quarter data if not available in database. If data already exists in database, return it from there.\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_statements_quarter'))==False or scrape_again==True:\n",
    "            self.financial_statements_quarter = self.scrape_the_data(url + '/income-statement?freq=Q')\n",
    "            self.store_data_in_database(data=self.financial_statements_quarter, name= (ticker_search + '_financial_statements_quarter'))\n",
    "        else:\n",
    "            self.financial_statements_quarter = self.get_from_database(name= (ticker_search + '_financial_statements_quarter'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_balance_sheet_quarter'))==False or scrape_again==True:\n",
    "            self.balance_sheet_quarter = self.scrape_the_data(url + '/balance-sheet?freq=Q')\n",
    "            self.store_data_in_database(data=self.balance_sheet_quarter, name= (ticker_search + '_balance_sheet_quarter'))\n",
    "        else:\n",
    "            self.balance_sheet_quarter = self.get_from_database(name= (ticker_search + '_balance_sheet_quarter'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_cash_flow_quarter'))==False or scrape_again==True:\n",
    "            self.cash_flow_quarter = self.scrape_the_data(url + '/cash-flow-statement?freq=Q')\n",
    "            self.store_data_in_database(data=self.cash_flow_quarter, name= (ticker_search + '_cash_flow_quarter'))\n",
    "        else:\n",
    "            self.cash_flow_quarter = self.get_from_database(name= (ticker_search + '_cash_flow_quarter'))\n",
    "\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_ratios_quarter'))==False or scrape_again==True:\n",
    "            self.financial_ratios_quarter = self.scrape_the_data(url + '/financial-ratios?freq=Q')\n",
    "            self.store_data_in_database(data=self.financial_ratios_quarter, name= (ticker_search + '_financial_ratios_quarter'))\n",
    "        else:\n",
    "            self.financial_ratios_quarter = self.get_from_database(name= (ticker_search + '_financial_ratios_quarter'))\n",
    "        \n",
    "        #scrape company anual data\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_statements_annual'))==False or scrape_again==True:\n",
    "            self.financial_statements_annual = self.scrape_the_data(url + '/income-statement?freq=A')\n",
    "            self.store_data_in_database(data=self.financial_statements_annual, name= (ticker_search + '_financial_statements_annual'))\n",
    "        else:\n",
    "            self.financial_statements_annual = self.get_from_database(name= (ticker_search + '_financial_statements_annual'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_balance_sheet_annual'))==False or scrape_again==True:\n",
    "            self.balance_sheet_annual = self.scrape_the_data(url + '/balance-sheet?freq=A')\n",
    "            self.store_data_in_database(data=self.balance_sheet_annual, name= (ticker_search + '_balance_sheet_annual'))\n",
    "        else:\n",
    "            self.balance_sheet_annual = self.get_from_database(name= (ticker_search + '_balance_sheet_annual'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_cash_flow_annual'))==False or scrape_again==True:\n",
    "            self.cash_flow_annual = self.scrape_the_data(url + '/cash-flow-statement?freq=A')\n",
    "            self.store_data_in_database(data=self.cash_flow_annual, name= (ticker_search + '_cash_flow_annual'))\n",
    "        else:\n",
    "            self.cash_flow_annual = self.get_from_database(name= (ticker_search + '_cash_flow_annual'))\n",
    "\n",
    "        if self.data_already_in_database(name= (ticker_search + '_financial_ratios_annual'))==False or scrape_again==True:\n",
    "            self.financial_ratios_annual = self.scrape_the_data(url + '/financial-ratios?freq=A')\n",
    "            self.store_data_in_database(data=self.financial_ratios_annual, name= (ticker_search + '_financial_ratios_annual'))\n",
    "        else:\n",
    "            self.financial_ratios_annual = self.get_from_database(name= (ticker_search + '_financial_ratios_annual'))\n",
    "\n",
    "\n",
    "    def get_company_page_url(self, ticker_search):\n",
    "        #get ticker data\n",
    "        tickers_url = 'https://www.macrotrends.net/assets/php/ticker_search_list.php?_=1664947632720'\n",
    "        data_tickers = requests.get(tickers_url)\n",
    "        data_tickers = data_tickers.text\n",
    "        data_tickers_json = json.loads(data_tickers)\n",
    "\n",
    "        #search for the company-url\n",
    "        for item in data_tickers_json:\n",
    "            # print(item['s'])\n",
    "            if ticker_search in item['s']: #example: AAPL/apple\n",
    "                company_page_url = item['s']\n",
    "                # print(\"company-url={}\".format(company_page_url))\n",
    "\n",
    "        return 'https://www.macrotrends.net/stocks/charts/' + company_page_url\n",
    "\n",
    "\n",
    "    def scrape_the_data(self, url):\n",
    "\n",
    "        page = requests.get(url)\n",
    "        page_lines = page.text.splitlines()\n",
    "        for line in page_lines:\n",
    "            if 'var originalData =' in line: #the line where all the data is storred\n",
    "                data = line #store the information in a variable\n",
    "                print(f'line={url, line[0:100]}')\n",
    "\n",
    "        data = data[20:-1] # remove the the unneeded informatino from the line\n",
    "        data_json = json.loads(data) #convert the line to a json-object\n",
    "\n",
    "        #the following vars are needed when looping through the json_\n",
    "        data_index = [] #collect the data-names\n",
    "        data_column = [] #collect the data-dates\n",
    "        data_values = [] #collect the data-values\n",
    "\n",
    "        #loop over \n",
    "        for item in data_json:\n",
    "\n",
    "            #reset temp-vars for the next loop\n",
    "            data_values_temp = [] #store data-values for current loop\n",
    "            data_column_temp = [] #store data-dates for current loop\n",
    "\n",
    "            for key in item.items() :\n",
    "                # print(key[0], key[1])\n",
    "\n",
    "                if (key[0] != 'field_name') and (key[0] != 'popup_icon'): # dates and values\n",
    "                    # print(key[0], key[1])\n",
    "                    data_column_temp.append(key[0]) #dates\n",
    "                    data_values_temp.append(key[1]) #values\n",
    "\n",
    "                elif key[0] == 'field_name': #data-names\n",
    "                    # print(key[1])\n",
    "                    parser.feed(key[1])\n",
    "                    # print(parser.output)\n",
    "                    data_index.append(parser.output) # xxx = \"<a href='/stocks/charts/TSLA/tesla/cost-goods-sold'>Cost Of Goods Sold</a>\"\n",
    "\n",
    "                elif key[0]== 'popup_icon': #data-graph link (not needed)\n",
    "                    continue\n",
    "                    print(key[1])\n",
    "\n",
    "            #add temp-vars to permanent ones\n",
    "            data_values.append(data_values_temp)\n",
    "            data_column.append(data_column_temp)\n",
    "\n",
    "\n",
    "        # pd.DataFrame(data=data_values, index=data_index, columns=data_column, dtype=None, copy=None)\n",
    "        company_data = pd.DataFrame(data=data_values, index=data_index, columns=data_column[0])\n",
    "        company_data.apply(self.fixData)\n",
    "\n",
    "        return company_data\n",
    "\n",
    "    #apply-function that goes over all dataframe-elements and converts them to numeric value if possible\n",
    "    def fixData(sekf, input_data):\n",
    "        \n",
    "        for i in range(len(input_data)):\n",
    "        \n",
    "            try:\n",
    "                input_data[i] = pd.to_numeric(input_data[i])\n",
    "                # print(type(input_data[i]), \"converted to numeric\")\n",
    "\n",
    "            except:\n",
    "                # pass\n",
    "                print(input_data[i], \"Can't convert to numeric\")\n",
    "            \n",
    "        return input_data\n",
    "        \n",
    "\n",
    "    def store_data_in_database(self, data, name):\n",
    "        database = \"company_database.db\"\n",
    "        conn = sqlite3.connect(database)\n",
    "        data.to_sql(name=name, con=conn, if_exists='replace')\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "    def data_already_in_database(self, name):\n",
    "\n",
    "        output = False\n",
    "        conn = sqlite3.connect('company_database.db')\n",
    "        c = conn.cursor()\n",
    "                    \n",
    "        #get the count of tables with the name\n",
    "        c.execute(''' SELECT count(name) FROM sqlite_master WHERE type='table' AND name='{}' '''.format(name))\n",
    "\n",
    "        #if the count is 1, then table exists\n",
    "        if c.fetchone()[0]==1:\n",
    "            # print('Table exists.', name)\n",
    "            output = True\n",
    "\t\t\t\n",
    "        #commit the changes to db\t\t\t\n",
    "        conn.commit()\n",
    "        #close the connection\n",
    "        conn.close()\n",
    "\n",
    "        # print(name, output)\n",
    "        return output\n",
    "\n",
    "    def get_from_database(self, name):\n",
    "        conn = sqlite3.connect('company_database.db')\n",
    "        output = pd.read_sql_query(f\"SELECT * from {name}\", conn) #get the data from database and put it in pandas-dataframe\n",
    "        output_index = output.set_index('index', inplace=False) #set the index-column as dataframe-index, needed because otherwise the dataframe index won't be parameter names but integers\n",
    "        # print(output)\n",
    "        # print(output1)\n",
    "        conn.close()\n",
    "        return output_index\n",
    "\n",
    "    # company_data.dtypes\n",
    "    # company_data.columns\n",
    "    # company_data.index\n",
    "\n",
    "    # company_data.loc['Revenue']\n",
    "    # company_data.loc['EPS - Earnings Per Share']\n",
    "\n",
    "    # company_data.columns = pd.to_datetime(company_data.columns) #change columns data-type to datetime.\n",
    "    # company_data.columns\n",
    "\n",
    "pepsi_data = ScrapeMacrotrend(ticker_search='PEP', scrape_again=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data = ScrapeMacrotrend('AAPL')\n",
    "tesla_data = ScrapeMacrotrend('TSLA')\n",
    "microsoft_data = ScrapeMacrotrend('MSFT')\n",
    "amazon_data = ScrapeMacrotrend('AMZN')\n",
    "# google_data = ScrapeMacrotrend('GOOG')\n",
    "\n",
    "# apple_data1 = ScrapeMacrotrend('AAPL')\n",
    "# tesla_data1 = ScrapeMacrotrend('TSLA')\n",
    "# microsoft_data1 = ScrapeMacrotrend('MSFT')\n",
    "# amazon_data1 = ScrapeMacrotrend(ticker_search='AMZN')\n",
    "\n",
    "#tesla_data.financial_statements_annual\n",
    "# print(amazon_data.financial_statements_quarter.index.to_list())\n",
    "# print(amazon_data1.financial_statements_quarter.index.to_list())\n",
    "\n",
    "# amazon_data.financial_statements_quarter.columns\n",
    "\n",
    "# amazon_data2 = amazon_data1.financial_statements_quarter.copy()\n",
    "# print(amazon_data2.columns)\n",
    "# amazon_data2.drop('index', axis=1, inplace=True) \n",
    "# amazon_data2.set_index('index', inplace=True)\n",
    "# print(amazon_data2.columns)\n",
    "\n",
    "# amazon_data.financial_statements_quarter\n",
    "# amazon_data1.financial_statements_quarter\n",
    "# amazon_data2\n",
    "\n",
    "# amazon_data3 = ScrapeMacrotrend(ticker_search='AMZN')\n",
    "# amazon_data3.financial_statements_quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46832d9-cc4e-4c87-9c83-76bec4211338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the data\n",
    "plt.figure(figsize=(20,8)) #set figure size\n",
    "\n",
    "# tesla_data.financial_ratios_quarter.loc['Current Ratio'].plot()\n",
    "# apple_data.financial_ratios_quarter.loc['Current Ratio'].plot()\n",
    "\n",
    "print(tesla_data.financial_statements_annual.index[0])\n",
    "param_name = tesla_data.financial_statements_annual.index[4] #get parameter name from dataframe columns\n",
    "\n",
    "tesla_data.financial_statements_annual.loc[param_name].plot()\n",
    "apple_data.financial_statements_annual.loc[param_name].plot()\n",
    "microsoft_data.financial_statements_annual.loc[param_name].plot()\n",
    "amazon_data.financial_statements_annual.loc[param_name].plot()\n",
    "google_data.financial_statements_annual.loc[param_name].plot()\n",
    "plt.plot()\n",
    "\n",
    "#invert x-axis (2009 on the left, 2022 on the right)\n",
    "ax = plt.gca()\n",
    "ax.invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccf1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get all ticker-urls and put them in the database\n",
    "\n",
    "class getAllCompanyTickers():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.tickers_data = self.download_tickers()\n",
    "        self.store_data_in_database(self.tickers_data, \"Macrotrends_Tickers_URLs\")\n",
    "\n",
    "    def download_tickers(self):\n",
    "\n",
    "        tickers_data =[]\n",
    "        #donwnload ticker-page\n",
    "        tickers_url = 'https://www.macrotrends.net/assets/php/ticker_search_list.php?_=1664947632720'\n",
    "        data_tickers = requests.get(tickers_url)\n",
    "        data_tickers = data_tickers.text\n",
    "        data_tickers_json = json.loads(data_tickers)\n",
    "\n",
    "        #search for the company-url\n",
    "        for item in data_tickers_json:\n",
    "            # print(item['s'])\n",
    "            tickers_data.append(item['s'])\n",
    "\n",
    "        output = pd.DataFrame(tickers_data)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def store_data_in_database(self, data, name):\n",
    "        database = \"company_database.db\"\n",
    "        conn = sqlite3.connect(database)\n",
    "        data.to_sql(name=name, con=conn, if_exists='replace',  index=False)\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "        \n",
    "output = getAllCompanyTickers()\n",
    "# print(output.tickers_data.iloc[1][0])\n",
    "ticker_num_rows= len(output.tickers_data)\n",
    "for i in range (150): #ticker_num_rows):\n",
    "    ticker_name = str(output.tickers_data.iloc[i][0]).split('/')[0]\n",
    "    print(ticker_name)\n",
    "    try:\n",
    "        ScrapeMacrotrend(ticker_name)\n",
    "    except:\n",
    "        print(f\"can't scrape{ticker_name}\")\n",
    "    time.sleep(0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5fea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c1ea65e26ef28b28e64095c9e5432f906157cd0ea853e6f943e47ec1b4a1819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
