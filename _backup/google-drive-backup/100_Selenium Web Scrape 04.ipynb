{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b8674-3a64-4411-8482-f28310839f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCRAPE MULTIPLE FINANCIAL PARAMETERS FROM SINGLE PAGE / V2 / Faster scrolling using drag&drop apprach\n",
    "#https://stackoverflow.com/questions/62119348/how-to-scroll-horizontally-using-selenium-chromedriver-in-python\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d96d4-8724-483f-abc2-6ad3457a4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo\n",
    "#Add Support for balanse-sheet,cashflow-statement,financial-ratios and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d804e-f8b5-41a3-ba8d-d034022a6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeMacrotrend:\n",
    "    \n",
    "    def __init__(self, ticker_name):\n",
    "        \n",
    "        self.start = time.time() #start timer\n",
    "        self.ticker_name = ticker_name #ticker or company name\n",
    "        \n",
    "        #innitialize and set chrome-webdriver options\n",
    "        self.chrome_options = Options()\n",
    "        #self.chrome_options.add_argument(\"--window-size=1000,1080\")\n",
    "        #self.chrome_options.add_argument(\"--headless\")\n",
    "        \n",
    "        self.driver = webdriver.Chrome(\"G:\\My Drive\\Investing\\Programming\\chromedriver.exe\", options=self.chrome_options)\n",
    "        self.driver.implicitly_wait(5)\n",
    "        self.driver.maximize_window()\n",
    "        self.base_url = \"https://www.macrotrends.net/\"\n",
    "        \n",
    "        self.ad_clicked = False\n",
    "        self.company_url = self.getCompanyURL()\n",
    "        \n",
    "        #scrape main pages\n",
    "        # self.income_statement = self.runScraper(self.company_url + \"/income-statement?freq=Q\")\n",
    "        # self.balance_sheet = self.runScraper(self.company_url + \"/balance-sheet?freq=Q\")\n",
    "        # self.cash_flow_statement = self.runScraper(self.company_url + \"/cash-flow-statement?freq=Q\")\n",
    "        self.temp_data = []\n",
    "        # self.financial_ratios = self.runScraper(self.company_url + \"/financial-ratios?freq=Q\")\n",
    "        self.financial_ratios = self.runFullTableScrape(self.company_url + \"/financial-ratios?freq=Q\")\n",
    "\n",
    "        \n",
    "        self.driver.close() #close chrome-webdriver\n",
    "        self.end = time.time() #stop timer\n",
    "        print('Complete time: {}s'.format(self.end - self.start))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def getCompanyURL(self): #this function finds the company url f.e. https://www.macrotrends.net/stocks/charts/AAPL/apple\n",
    "        self.driver.get(self.base_url)\n",
    "        self.search_box = self.driver.find_element_by_css_selector(\"input.js-typeahead\")\n",
    "        self.search_box.send_keys(self.ticker_name)\n",
    "        \n",
    "        #get company url\n",
    "        self.company_url = self.driver.find_element_by_xpath(\"//li[1]/a\") #xpath element of the company urls\n",
    "        self.company_url = self.company_url.get_attribute('href') #get the href-value\n",
    "        self.company_url = self.company_url.rsplit(\"/\", 1)[0] #split url to remove unnecesery data\n",
    "        \n",
    "        return self.company_url\n",
    "        \n",
    "        \n",
    "    def runScraper(self, url):\n",
    "        \n",
    "        #scraper variables\n",
    "        self.periods_table_prev_last_elem = -1 #previously(before scrolling) last scraped element of periods-table\n",
    "        self.periods_table_current_last_elem = 0 #current(after scrolling) last scraped element of periods-table\n",
    "        self.main_table_prev_last_elem = -1  #previously(before scrolling) last scraped element of main-table\n",
    "        self.main_table_current_last_elem = 0 #current(after scrolling) last scraped element of main-table\n",
    "\n",
    "        #data-storring variables\n",
    "        self.periods_table_data = [] #store data from periods table (annual or quarter)\n",
    "        self.main_table_data = [] #store data from the main-table like revenue, \n",
    "        self.all_scraped_data = pd.DataFrame()\n",
    "        \n",
    "        self.driver.get(url)\n",
    "\n",
    "        #find advertise window button and click it\n",
    "        if self.ad_clicked == False:\n",
    "            self.ad_button = self.driver.find_element_by_xpath('//button[@class=\"Button__StyledButton-a1qza5-0 cUAUIG\"]')\n",
    "            self.ad_button.click()\n",
    "            self.ad_clicked = True\n",
    "\n",
    "\n",
    "        self.horizontal_bar_width = self.driver.find_element_by_id('jqxScrollOuterWraphorizontalScrollBarjqxgrid').rect['width']\n",
    "        self.slider = self.driver.find_element_by_id('jqxScrollThumbhorizontalScrollBarjqxgrid')\n",
    "        \n",
    "        \n",
    "        #get table-parameter-names\n",
    "        full_table_params = []\n",
    "        full_table_params_and_values = []\n",
    "        full_table = self.driver.find_element_by_css_selector(\"#contentjqxgrid\")\n",
    "        full_table = full_table.text.splitlines()\n",
    "        for item in full_table:\n",
    "            if item[-1].isdigit()==False and item[-1] != \"-\" and item !=\"www.jqwidgets.com\" :\n",
    "                full_table_params.append(item)\n",
    "\n",
    "        j=-1\n",
    "        for item in full_table:\n",
    "            if item == \"www.jqwidgets.com\":\n",
    "                continue\n",
    "            elif item in full_table_params:\n",
    "                j=j+1\n",
    "                full_table_params_and_values.append([item])\n",
    "                continue\n",
    "            full_table_params_and_values[j].append(item)\n",
    "\n",
    "\n",
    "        print(full_table_params_and_values)\n",
    "        self.driver.close()\n",
    "        raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "        #scroll table from left to right and scrape data\n",
    "        while (self.periods_table_prev_last_elem != self.periods_table_current_last_elem): #and (self.main_table_prev_last_elem != self.main_table_current_last_elem):\n",
    "            \n",
    "            ##########################################################################\n",
    "            # full_table = self.driver.find_element_by_xpath(\"//div[@id='jqxgrid']\")\n",
    "            # full_table = self.driver.find_element_by_css_selector(\"#contentjqxgrid\")\n",
    "            # full_table = full_table.text.splitlines()\n",
    "            # self.temp_data.append(full_table)\n",
    "            # print(full_table)\n",
    "            ###########################################################################\n",
    "\n",
    "            #set the last element from the last scrape as previous one\n",
    "            self.periods_table_prev_last_elem = self.periods_table_current_last_elem\n",
    "            self.main_table_prev_last_elem = self.main_table_current_last_elem\n",
    "\n",
    "            # self.periods_table = self.driver.find_element_by_xpath('//*[@id=\"columntablejqxgrid\"]') \n",
    "            self.periods_table = self.driver.find_element_by_xpath('//*[@id=\"contentjqxgrid\"]/div[1]') #this is the header row in the table, containing the dates.\n",
    "            # print(self.periods_table.text)\n",
    "            #parameters_table = self.driver.find_element_by_xpath('//*[@id=\"contentjqxgrid\"]/div[2]')\n",
    "            self.periods_table_split = self.periods_table.text.splitlines() #split the periods to array\n",
    "            self.periods_table_current_last_elem = self.periods_table_split[-1] #get the last element from the table\n",
    "            # print(len(self.periods_table_split), \"periods\")\n",
    "            # print('last-element={}'.format(self.periods_table_current_last_elem))\n",
    "\n",
    "            # main_table = self.driver.find_elements_by_xpath('//div[@role=\"row\"]') #get the main table\n",
    "            main_table = self.driver.find_elements_by_xpath('//*[@id=\"contentjqxgrid\"]/div[2]/div/div') #get the main table\n",
    "            self.main_table_current_last_elem = main_table[0].text.splitlines()[-1]\n",
    "            # print(len(main_table[0].text.splitlines()), \"main\")\n",
    "            #print(self.main_table_current_last_elem)\n",
    "            \n",
    "            #this is the innitial position of the table, no scrolling has been executed yet\n",
    "            if self.periods_table_prev_last_elem == 0: \n",
    "                #add scraped elements of periods table to a temp-variable \n",
    "                self.periods_table_data.extend(self.periods_table_split) \n",
    "                \n",
    "                #add the scraped elements of main-table to a temp-variable\n",
    "                for i in range (len(main_table)): #add all parameter to table\n",
    "                    main_table_split = main_table[i].text.splitlines()\n",
    "                    self.main_table_data.append(main_table_split)\n",
    "\n",
    "            else:\n",
    "                #find the previous last element when the periods-table is scrolled to the right\n",
    "                self.periods_table_prev_last_elem_index = self.periods_table_split.index(self.periods_table_prev_last_elem)\n",
    "                #add the new elements after the periods-table is scrolled to the right\n",
    "                self.periods_table_data.extend(self.periods_table_split[self.periods_table_prev_last_elem_index+1:]) \n",
    "                # print(self.periods_table_split)\n",
    "                \n",
    "                #find the previous last element when the main-table is scrolled to the right\n",
    "                self.main_table_prev_last_elem_index = main_table[0].text.splitlines().index(self.main_table_prev_last_elem) \n",
    "                # print(main_table[0].text.splitlines())\n",
    "                #add the new elements after the main-table is scrolled to the right\n",
    "                for row in range (len(main_table)): #add the new data to the table after scrolling table to the right\n",
    "                    main_table_split = main_table[row].text.splitlines()\n",
    "                    self.main_table_data[row].extend(main_table_split[self.main_table_prev_last_elem_index+1:])\n",
    "                \n",
    "\n",
    "\n",
    "                # raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "            # Ensure the slider is in view\n",
    "            self.slider.location_once_scrolled_into_view\n",
    "            #scroll table to the right\n",
    "            ActionChains(self.driver).click_and_hold(self.slider).move_by_offset(self.horizontal_bar_width/5, 0).release().perform()\n",
    "\n",
    "        \n",
    "        #add the scraped data to pandas dataframe\n",
    "        for i in range (len(self.main_table_data)):\n",
    "            #create temp dataframe with scraped data\n",
    "            # print(self.main_table_data[i], self.periods_table_data)\n",
    "            data = pd.DataFrame([self.main_table_data[i][1:]], columns=self.periods_table_data[1:], index=[self.main_table_data[i][0]]) \n",
    "            \n",
    "            #append temp-dataframe row to global dataframe\n",
    "            self.all_scraped_data = pd.concat([self.all_scraped_data, data]) \n",
    "\n",
    "        \n",
    "        #return scraped data\n",
    "        return self.all_scraped_data\n",
    "    \n",
    "    def runFullTableScrape(self, url):\n",
    "\n",
    "        self.driver.get(url)\n",
    "\n",
    "        #variables\n",
    "        full_table_params = [] #collect table parameters - Periods, Revenue, Cost Of Goods Sold ..\n",
    "        full_table_params_and_values = [] #collect parameters and values\n",
    "        full_table_params_and_values_set = [] #store scraped data as array-of-sets instead of array-of-arrays\n",
    "\n",
    "        #find advertise window button and click it\n",
    "        if self.ad_clicked == False:\n",
    "            self.ad_button = self.driver.find_element_by_xpath('//button[@class=\"Button__StyledButton-a1qza5-0 cUAUIG\"]')\n",
    "            self.ad_button.click()\n",
    "            self.ad_clicked = True\n",
    "\n",
    "\n",
    "        self.horizontal_bar_width = self.driver.find_element_by_id('jqxScrollOuterWraphorizontalScrollBarjqxgrid').rect['width']\n",
    "        self.slider = self.driver.find_element_by_id('jqxScrollThumbhorizontalScrollBarjqxgrid')\n",
    "\n",
    "        while True:\n",
    "\n",
    "            #get table-parameter-names\n",
    "            full_table = self.driver.find_element_by_css_selector(\"#contentjqxgrid\")\n",
    "            full_table = full_table.text.splitlines()\n",
    "            for item in full_table:\n",
    "                if item[-1].isdigit()==False and item[-1] != \"-\" and item !=\"www.jqwidgets.com\" :\n",
    "                    full_table_params.append(item)\n",
    "\n",
    "            #get table parameters names and values\n",
    "            j=-1\n",
    "            for item in full_table:\n",
    "                if item == \"www.jqwidgets.com\":\n",
    "                    continue\n",
    "                elif item in full_table_params:\n",
    "                    j=j+1\n",
    "                    full_table_params_and_values.append([item])\n",
    "                    continue\n",
    "                full_table_params_and_values[j].append(item)\n",
    "\n",
    "            #convert data from array-of-arrays to array-of-sets\n",
    "            for i in range(len(full_table_params_and_values)):\n",
    "                temp_set = set(full_table_params_and_values[i])\n",
    "                full_table_params_and_values_set.append(item)\n",
    "\n",
    "            # print(full_table_params_and_values)\n",
    "            self.driver.close()\n",
    "            raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "\n",
    "tesla = ScrapeMacrotrend(\"tesla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b67a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company-url=AAPL/apple\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2022-06-30     82959.0\n",
       "2022-03-31     97278.0\n",
       "2021-12-31    123945.0\n",
       "2021-09-30     83360.0\n",
       "2021-06-30     81434.0\n",
       "2021-03-31     89584.0\n",
       "2020-12-31    111439.0\n",
       "2020-09-30     64698.0\n",
       "2020-06-30     59685.0\n",
       "2020-03-31     58313.0\n",
       "2019-12-31     91819.0\n",
       "2019-09-30     64040.0\n",
       "2019-06-30     53809.0\n",
       "2019-03-31     58015.0\n",
       "2018-12-31     84310.0\n",
       "2018-09-30     62900.0\n",
       "2018-06-30     53265.0\n",
       "2018-03-31     61137.0\n",
       "2017-12-31     88293.0\n",
       "2017-09-30     52579.0\n",
       "2017-06-30     45408.0\n",
       "2017-03-31     52896.0\n",
       "2016-12-31     78351.0\n",
       "2016-09-30     46852.0\n",
       "2016-06-30     42358.0\n",
       "2016-03-31     50557.0\n",
       "2015-12-31     75872.0\n",
       "2015-09-30     51501.0\n",
       "2015-06-30     49605.0\n",
       "2015-03-31     58010.0\n",
       "2014-12-31     74599.0\n",
       "2014-09-30     42123.0\n",
       "2014-06-30     37432.0\n",
       "2014-03-31     45646.0\n",
       "2013-12-31     57594.0\n",
       "2013-09-30     37472.0\n",
       "2013-06-30     35323.0\n",
       "2013-03-31     43603.0\n",
       "2012-12-31     54512.0\n",
       "2012-09-30     35966.0\n",
       "2012-06-30     35023.0\n",
       "2012-03-31     39186.0\n",
       "2011-12-31     46333.0\n",
       "2011-09-30     28270.0\n",
       "2011-06-30     28571.0\n",
       "2011-03-31     24667.0\n",
       "2010-12-31     26741.0\n",
       "2010-09-30     20343.0\n",
       "2010-06-30     15700.0\n",
       "2010-03-31     13499.0\n",
       "2009-12-31     15683.0\n",
       "2009-09-30     12207.0\n",
       "2009-06-30      9734.0\n",
       "2009-03-31      9084.0\n",
       "Name: Revenue, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "\n",
    "#HTML parser that help to parse html-strings\n",
    "#https://www.educative.io/answers/what-is-the-html-parser-in-python\n",
    "class Parser(HTMLParser):\n",
    "  def handle_data(self, data):\n",
    "    self.output = data\n",
    "parser = Parser()\n",
    "\n",
    "ticker_search = 'AAPL'\n",
    "\n",
    "#get ticker data\n",
    "tickers_url = 'https://www.macrotrends.net/assets/php/ticker_search_list.php?_=1664947632720'\n",
    "data_tickers = requests.get(tickers_url)\n",
    "data_tickers = data_tickers.text\n",
    "data_tickers_json = json.loads(data_tickers)\n",
    "\n",
    "#search for the company-url\n",
    "for item in data_tickers_json:\n",
    "    # print(item['s'])\n",
    "    if ticker_search in item['s']: #example: AAPL/apple\n",
    "        company_page_url = item['s']\n",
    "        print(\"company-url={}\".format(company_page_url))\n",
    "\n",
    "# url = 'https://www.macrotrends.net/stocks/charts/TSLA/tesla/income-statement?freq=Q'\n",
    "url = 'https://www.macrotrends.net/stocks/charts/' + company_page_url + '/income-statement?freq=Q'\n",
    "\n",
    "\n",
    "page = requests.get(url)\n",
    "page_lines = page.text.splitlines()\n",
    "for line in page_lines:\n",
    "    if 'var originalData =' in line: #the line where all the data is storred\n",
    "        data = line #store the information in a variable\n",
    "\n",
    "data = data[20:-1] # remove the the unneeded informatino from the line\n",
    "data_json = json.loads(data) #convert the line to a json-object\n",
    "\n",
    "#the following vars are needed when looping through the json_\n",
    "data_index = [] #collect the data-names\n",
    "data_column = [] #collect the data-dates\n",
    "data_values = [] #collect the data-values\n",
    "\n",
    "#loop over \n",
    "for item in data_json:\n",
    "\n",
    "    #reset temp-vars for the next loop\n",
    "    data_values_temp = [] #store data-values for current loop\n",
    "    data_column_temp = [] #store data-dates for current loop\n",
    "\n",
    "    for key in item.items() :\n",
    "        # print(key[0], key[1])\n",
    "\n",
    "        if (key[0] != 'field_name') and (key[0] != 'popup_icon'): # dates and values\n",
    "            # print(key[0], key[1])\n",
    "            data_column_temp.append(key[0]) #dates\n",
    "            data_values_temp.append(key[1]) #values\n",
    "\n",
    "        elif key[0] == 'field_name': #data-names\n",
    "            # print(key[1])\n",
    "            parser.feed(key[1])\n",
    "            # print(parser.output)\n",
    "            data_index.append(parser.output) # xxx = \"<a href='/stocks/charts/TSLA/tesla/cost-goods-sold'>Cost Of Goods Sold</a>\"\n",
    "\n",
    "        elif key[0]== 'popup_icon': #data-graph link (not needed)\n",
    "            continue\n",
    "            print(key[1])\n",
    "\n",
    "    #add temp-vars to permanent ones\n",
    "    data_values.append(data_values_temp)\n",
    "    data_column.append(data_column_temp)\n",
    "\n",
    " \n",
    "\n",
    "# pd.DataFrame(data=data_values, index=data_index, columns=data_column, dtype=None, copy=None)\n",
    "company_data = pd.DataFrame(data=data_values, index=data_index, columns=data_column[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#apply-function that goes over all dataframe-elements and converts them to numeric value if possible\n",
    "def fixData(input_data):\n",
    "    \n",
    "    for i in range(len(input_data)):\n",
    "      \n",
    "        try:\n",
    "            input_data[i] = pd.to_numeric(input_data[i])\n",
    "            # print(type(input_data[i]), \"converted to numeric\")\n",
    "\n",
    "        except:\n",
    "            # pass\n",
    "            print(input_data[i], \"Can't convert to numeric\")\n",
    "        \n",
    "    return input_data\n",
    "    \n",
    "company_data.apply(fixData)\n",
    "\n",
    "# company_data[\"Revenue\"].plot()\n",
    "# company_data[\"Gross Profit\"].plot()\n",
    "# plt.show()\n",
    "\n",
    "# company_data.dtypes\n",
    "# company_data.columns\n",
    "# company_data.index\n",
    "# url\n",
    "# company_data.loc['Revenue']\n",
    "# company_data.loc['EPS - Earnings Per Share']\n",
    "\n",
    "# company_data.columns = pd.to_datetime(company_data.columns) #change columns data-type to datetime.\n",
    "# company_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46832d9-cc4e-4c87-9c83-76bec4211338",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.financial_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b675dc3-dadd-4bdd-be32-13e204e1c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7673c4-8eb5-43ad-9bd9-242e5bf34931",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677141ef-ba7c-4855-8d9f-cdd2511a836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \"$\" from the values\n",
    "def fixData(input_data):\n",
    "    \n",
    "    for i in range(len(input_data)):\n",
    "        input_data[i]=input_data[i].replace(\"$\",\"\")\n",
    "        input_data[i]=input_data[i].replace(\",\",\".\")\n",
    "        # try:\n",
    "        #     input_data[i] =  float(input_data[i])\n",
    "        #     # print(type(input_data[i]), input_data[i])\n",
    "        # except:\n",
    "        #     pass\n",
    "        #     # print(input_data[i],\"can't convert to float\")\n",
    "        \n",
    "        try:\n",
    "            input_data[i] = pd.to_numeric(input_data[i])\n",
    "            # print(type(input_data[i]), \"converted to numeric\")\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # print(\"Can't convert to numeric\")\n",
    "        \n",
    "    return input_data\n",
    "    \n",
    "\n",
    "c_data = company_data.copy()\n",
    "c_data.apply(fixData)\n",
    "# c_data.apply(pd.to_numeric)\n",
    "c_data = c_data.T #transpose the table\n",
    "# c_data.index.to_datetime()\n",
    "c_data.index = pd.to_datetime(c_data.index) #change index data-type to datetime.\n",
    "c_data\n",
    "\n",
    "# c_data[\"Revenue\"] = pd.to_numeric(c_data[\"Revenue\"]) #convert data-type from string to number\n",
    "# c_data[\"Gross Profit\"] = pd.to_numeric(c_data[\"Gross Profit\"]) #convert data-type from string to number\n",
    "c_data[\"Revenue\"].plot()\n",
    "c_data[\"Gross Profit\"].plot()\n",
    "plt.show()\n",
    "\n",
    "# company_data\n",
    "#DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)\n",
    "# df = pd.DataFrame({\n",
    "#    'pig': [20, 18, 489, 675, 1776],\n",
    "#    'horse': [4, 25, 281, 600, 1900]\n",
    "#    }, index=[1990, 1997, 2003, 2009, 2014])\n",
    "# lines = df.plot.line()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95c77e-b7fb-474b-970d-f4dd1edfb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data.T.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5234c3a68123d47bedd5252b78f01a988a4bd5dcba8aa660c71661565635d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
