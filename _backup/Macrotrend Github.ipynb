{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0c7c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Tickers (separated by \",\":  aapl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    186\u001b[0m         frxsr[last_key] \u001b[38;5;241m=\u001b[39m [i]\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m#creating dataframes\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m fszdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfszsr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m fsxdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(fsxsr)\n\u001b[0;32m    190\u001b[0m bszdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(bszsr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#https://github.com/capuccino26/MacroTrends-Scraping/blob/main/MACRO_TRENDS_SCRAPING.ipynb\n",
    "\n",
    "#pip install openpyxl\n",
    "#pip install selenium\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import re\n",
    "#pip install numpy\n",
    "import numpy as np\n",
    "#pip install pandas\n",
    "import pandas as pd\n",
    "#pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "#pip install pandas_datareader\n",
    "import pandas_datareader.data as web\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import os\n",
    "#input tickers creating a list with all input data\n",
    "tickers = input('Tickers (separated by \",\": ')\n",
    "z = list(map(str,tickers.split(',')))\n",
    "#getting correct urls for each ticker\n",
    "for i in z:\n",
    "    a=i\n",
    "    print(a)\n",
    "    driver = webdriver.Firefox()\n",
    "    url = 'https://www.macrotrends.net/'\n",
    "    driver.get(url)\n",
    "    box = driver.find_element(By.CSS_SELECTOR, \".js-typeahead\")\n",
    "    box.send_keys(a)\n",
    "    time.sleep(1)\n",
    "    box.send_keys(Keys.DOWN, Keys.RETURN)\n",
    "    time.sleep(1)\n",
    "    geturl = driver.current_url\n",
    "    time.sleep(4)\n",
    "    driver.quit()\n",
    "    #check if the ticker is available in MacroTrends\n",
    "    if \"stocks\" in geturl:\n",
    "        geturlsp = geturl.split(\"/\", 10)\n",
    "        geturlf = url+\"stocks/charts/\"+geturlsp[5]+\"/\"+geturlsp[6]+\"/\"\n",
    "        driver = webdriver.Firefox()\n",
    "        fsurl = geturlf+\"financial-statements\"\n",
    "        driver.get(fsurl)\n",
    "        #check if the data in the ticker is available\n",
    "        if driver.find_elements(By.CSS_SELECTOR, \"div.jqx-grid-column-header:nth-child(1) > div:nth-child(1) > div:nth-child(1) > span:nth-child(1)\"):\n",
    "            #financial-statements\n",
    "            driver.set_window_size(2000, 2000)\n",
    "            time.sleep(10)\n",
    "            fsa = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            da = driver.find_element(By.CSS_SELECTOR, \"#columntablejqxgrid\").text\n",
    "            arrow = driver.find_element(By.CSS_SELECTOR, \".jqx-icon-arrow-right\")\n",
    "            webdriver.ActionChains(driver).click_and_hold(arrow).perform()\n",
    "            time.sleep(4)\n",
    "            fsb = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            db = driver.find_element(By.CSS_SELECTOR, \"#columntablejqxgrid\").text\n",
    "            #balance-sheet\n",
    "            bsurl = geturlf+\"balance-sheet\"\n",
    "            driver.get(bsurl)\n",
    "            driver.set_window_size(2000, 2000)\n",
    "            bsa = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            arrow = driver.find_element(By.CSS_SELECTOR, \".jqx-icon-arrow-right\")\n",
    "            webdriver.ActionChains(driver).click_and_hold(arrow).perform()\n",
    "            time.sleep(4)\n",
    "            bsb = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            #cash-flow\n",
    "            bsurl = geturlf+\"cash-flow-statement\"\n",
    "            driver.get(bsurl)\n",
    "            driver.set_window_size(2000, 2000)\n",
    "            cfa = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            arrow = driver.find_element(By.CSS_SELECTOR, \".jqx-icon-arrow-right\")\n",
    "            webdriver.ActionChains(driver).click_and_hold(arrow).perform()\n",
    "            time.sleep(4)\n",
    "            cfb = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            #financial-ratio\n",
    "            bsurl = geturlf+\"financial-ratios\"\n",
    "            driver.get(bsurl)\n",
    "            driver.set_window_size(2000, 2000)\n",
    "            fra = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            arrow = driver.find_element(By.CSS_SELECTOR, \".jqx-icon-arrow-right\")\n",
    "            webdriver.ActionChains(driver).click_and_hold(arrow).perform()\n",
    "            time.sleep(4)\n",
    "            frb = driver.find_element(By.CSS_SELECTOR, \"#contenttablejqxgrid\").text\n",
    "            driver.quit()\n",
    "            #remove symbols from variables\n",
    "            fsz = fsa.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            fsx = fsb.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            bsz = bsa.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            bsx = bsb.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            cfz = cfa.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            cfx = cfb.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            frz = fra.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            frx = frb.replace(\".\",\"\").replace(\"$\",\"\").replace(\",\",\"\")\n",
    "            dz = da.replace(\"$\",\"\").replace(\".\",\"\")\n",
    "            dx = db.replace(\"$\",\"\").replace(\".\",\"\")\n",
    "            #split variables into lists\n",
    "            fszs = fsz.splitlines()\n",
    "            fsxs = fsx.splitlines()\n",
    "            bszs = bsz.splitlines()\n",
    "            bsxs = bsx.splitlines()\n",
    "            cfzs = cfz.splitlines()\n",
    "            cfxs = cfx.splitlines()\n",
    "            frzs = frz.splitlines()\n",
    "            frxs = frx.splitlines()\n",
    "            dzs = dz.splitlines()\n",
    "            dxs = dx.splitlines()\n",
    "            #removing title from dates dataframe\n",
    "            dzsr = np.delete(dzs, (0), axis=0)\n",
    "            dxsr = np.delete(dxs, (0), axis=0)\n",
    "            #define headers for data\n",
    "            last_key = None\n",
    "            fszsr = {}\n",
    "            for i in fszs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in fszsr:\n",
    "                    fszsr[last_key].append(i)\n",
    "                else:\n",
    "                    fszsr[last_key] = [i] \n",
    "            last_key = None\n",
    "            fsxsr = {}\n",
    "            for i in fsxs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in fsxsr:\n",
    "                    fsxsr[last_key].append(i)\n",
    "                else:\n",
    "                    fsxsr[last_key] = [i]\n",
    "            last_key = None\n",
    "            bszsr = {}\n",
    "            for i in bszs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in bszsr:\n",
    "                    bszsr[last_key].append(i)\n",
    "                else:\n",
    "                    bszsr[last_key] = [i]  \n",
    "            last_key = None\n",
    "            bsxsr = {}\n",
    "            for i in bsxs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in bsxsr:\n",
    "                    bsxsr[last_key].append(i)\n",
    "                else:\n",
    "                    bsxsr[last_key] = [i]\n",
    "            last_key = None\n",
    "            cfzsr = {}\n",
    "            for i in cfzs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in cfzsr:\n",
    "                    cfzsr[last_key].append(i)\n",
    "                else:\n",
    "                    cfzsr[last_key] = [i]   \n",
    "            last_key = None\n",
    "            cfxsr = {}\n",
    "            for i in cfxs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in cfxsr:\n",
    "                    cfxsr[last_key].append(i)\n",
    "                else:\n",
    "                    cfxsr[last_key] = [i]\n",
    "            last_key = None\n",
    "            frzsr = {}\n",
    "            for i in frzs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in frzsr:\n",
    "                    frzsr[last_key].append(i)\n",
    "                else:\n",
    "                    frzsr[last_key] = [i]  \n",
    "            last_key = None\n",
    "            frxsr = {}\n",
    "            for i in frxs:\n",
    "                if not (i.isnumeric() or i == '-' or i.startswith('-')):\n",
    "                    last_key = i\n",
    "                elif last_key in frxsr:\n",
    "                    frxsr[last_key].append(i)\n",
    "                else:\n",
    "                    frxsr[last_key] = [i]\n",
    "            #creating dataframes\n",
    "            fszdf = pd.DataFrame(fszsr)\n",
    "            fsxdf = pd.DataFrame(fsxsr)\n",
    "            bszdf = pd.DataFrame(bszsr)\n",
    "            bsxdf = pd.DataFrame(bsxsr)\n",
    "            cfzdf = pd.DataFrame(cfzsr)\n",
    "            cfxdf = pd.DataFrame(cfxsr)\n",
    "            frzdf = pd.DataFrame(frzsr)\n",
    "            frxdf = pd.DataFrame(frxsr)\n",
    "            dzsrf = pd.DataFrame(dzsr)\n",
    "            dxsrf = pd.DataFrame(dxsr)\n",
    "            #treating dataframes\n",
    "            fszdff = fszdf.replace(\"-\",\"0\")\n",
    "            fszdff = fszdff.astype(float)\n",
    "            fsxdff = fsxdf.replace(\"-\",\"0\")\n",
    "            fsxdff = fsxdff.astype(float)\n",
    "            bszdff = bszdf.replace(\"-\",\"0\")\n",
    "            bszdff = bszdff.astype(float)\n",
    "            bsxdff = bsxdf.replace(\"-\",\"0\")\n",
    "            bsxdff = bsxdff.astype(float)\n",
    "            cfzdff = cfzdf.replace(\"-\",\"0\")\n",
    "            cfzdff = cfzdff.astype(float)\n",
    "            cfxdff = cfxdf.replace(\"-\",\"0\")\n",
    "            cfxdff = cfxdff.astype(float)\n",
    "            frzdff = frzdf.replace(\"-\",\"0\")\n",
    "            frzdff = frzdff.astype(float)\n",
    "            frxdff = frxdf.replace(\"-\",\"0\")\n",
    "            frxdff = frxdff.astype(float)\n",
    "            #naming dates dataframe\n",
    "            ddzsrf = dzsrf.set_axis([\"Dates\"], axis=1)\n",
    "            ddxsrf = dxsrf.set_axis([\"Dates\"], axis=1)\n",
    "            #merging dataframes\n",
    "            fszdffd = ddzsrf.merge(fszdff, left_index=True, right_index=True)\n",
    "            fsxdffd = ddxsrf.merge(fsxdff, left_index=True, right_index=True)\n",
    "            bszdffd = ddzsrf.merge(bszdff, left_index=True, right_index=True)\n",
    "            bsxdffd = ddxsrf.merge(bsxdff, left_index=True, right_index=True)\n",
    "            cfzdffd = ddzsrf.merge(cfzdff, left_index=True, right_index=True)\n",
    "            cfxdffd = ddxsrf.merge(cfxdff, left_index=True, right_index=True)\n",
    "            frzdffd = ddzsrf.merge(frzdff, left_index=True, right_index=True)\n",
    "            frxdffd = ddxsrf.merge(frxdff, left_index=True, right_index=True)\n",
    "            #defining dates as rows headers\n",
    "            fszn = fszdffd.set_index(\"Dates\")\n",
    "            fsxn = fsxdffd.set_index(\"Dates\")\n",
    "            bszn = bszdffd.set_index(\"Dates\")\n",
    "            bsxn = bsxdffd.set_index(\"Dates\")\n",
    "            cfzn = cfzdffd.set_index(\"Dates\")\n",
    "            cfxn = cfxdffd.set_index(\"Dates\")\n",
    "            frzn = frzdffd.set_index(\"Dates\")\n",
    "            frxn = frxdffd.set_index(\"Dates\")\n",
    "            #concatenate whole data\n",
    "            fsconcatdd = pd.concat([fszn,fsxn])\n",
    "            fsdados = fsconcatdd.drop_duplicates()\n",
    "            bsconcatdd = pd.concat([bszn,bsxn])\n",
    "            bsdados = bsconcatdd.drop_duplicates()\n",
    "            cfconcatdd = pd.concat([cfzn,cfxn])\n",
    "            cfdados = cfconcatdd.drop_duplicates()\n",
    "            frconcatdd = pd.concat([frzn,frxn])\n",
    "            frdados = frconcatdd.drop_duplicates()\n",
    "            #creating final dataframe\n",
    "            ca = fsdados.merge(bsdados, left_index=True, right_index=True)\n",
    "            cb = ca.merge(cfdados, left_index=True, right_index=True)\n",
    "            complete = cb.merge(frdados, left_index=True, right_index=True)\n",
    "            #managing plots\n",
    "            fig1, f1_axes = plt.subplots(ncols=2, nrows=2, figsize=(30,20))\n",
    "            fig1.suptitle (a, size=50)\n",
    "            f1_axes[0, 0].plot(complete['Revenue'], lw=2, marker='.', markersize=10, label=\"Revenue\")\n",
    "            f1_axes[0, 0].plot(complete['Gross Profit'], lw=2, marker='.', markersize=10, label=\"Gross Profit\")\n",
    "            f1_axes[0, 0].plot(complete['Net Income'], lw=2, marker='.', markersize=10, label=\"Net Income\")\n",
    "            f1_axes[0, 0].plot(complete['EBITDA'], lw=2, marker='.', markersize=10, label=\"EBITDA\")\n",
    "            f1_axes[0, 0].plot(complete['Total Assets'], lw=2, marker='.', markersize=10, label=\"Total Assets\")\n",
    "            f1_axes[0, 0].plot(complete['Total Liabilities'], lw=2, marker='.', markersize=10, label=\"Total Liabilities\")\n",
    "            f1_axes[0, 0].plot(complete['Total Depreciation And Amortization - Cash Flow'], lw=2, marker='.', markersize=10, label=\"Cash Flow\")\n",
    "            f1_axes[0, 0].plot(complete['Net Cash Flow'], lw=2, marker='.', markersize=10, label=\"Net Cash Flow\")\n",
    "            f1_axes[0, 1].plot(complete['EPS - Earnings Per Share'], lw=2, marker='.', markersize=10, label=\"EPS\")\n",
    "            f1_axes[1, 0].plot(complete['ROE - Return On Equity'], lw=2, marker='.', markersize=10, label=\"ROE\")\n",
    "            f1_axes[1, 0].plot(complete['ROA - Return On Assets'], lw=2, marker='.', markersize=10, label=\"ROA\")\n",
    "            f1_axes[1, 0].plot(complete['ROI - Return On Investment'], lw=2, marker='.', markersize=10, label=\"ROI\")\n",
    "            f1_axes[1, 1].plot(complete['Shares Outstanding'], lw=2, marker='.', markersize=10, label=\"Shares Outstanding\")\n",
    "            f1_axes[0, 0].legend()\n",
    "            f1_axes[0, 0].invert_xaxis()\n",
    "            f1_axes[0, 1].legend()\n",
    "            f1_axes[0, 1].invert_xaxis()\n",
    "            f1_axes[1, 0].legend()\n",
    "            f1_axes[1, 0].invert_xaxis()\n",
    "            f1_axes[1, 1].legend()\n",
    "            f1_axes[1, 1].invert_xaxis()\n",
    "            #creating folder for data and images\n",
    "            if not os.path.exists(\"STOCKUS/\"+a):\n",
    "                os.makedirs(\"STOCKUS/\"+a)\n",
    "            plt.savefig(\"STOCKUS/\"+a+\"/\"+a+\"data.png\")\n",
    "            complete.to_excel(os.path.join(\"STOCKUS/\"+a, geturlsp[5]+\".xlsx\"),sheet_name=geturlsp[5])\n",
    "            #confirmation message for ticker that exists and have data\n",
    "            print(\"SUCCESS\")\n",
    "        #error message for ticker that exists but have no data\n",
    "        else:\n",
    "            driver.quit()\n",
    "            print(\"EMPTY TICKER\")\n",
    "    #error message for ticker that doesn't exist\n",
    "    else:\n",
    "            print(\"INVALID TICKER\")\n",
    "#final message\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111a18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
